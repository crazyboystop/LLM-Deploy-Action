<div align="center">
    <h1>LLM Deploy Action</h1>
</div>

è‡ªä»ChatGPTä¸ºä»£è¡¨çš„å¤§è¯­è¨€æ¨¡å‹(Large Language Model, LLM)å…´èµ·ä¹‹åï¼Œå„å¤§å·¨å¤´å…¬å¸ã€åˆ›ä¸šå…¬å¸ã€ç§‘ç ”æœºæ„éƒ½åœ¨å·LLMè®­ç»ƒï¼Œå¿™ç€å‘å¸ƒè‡ªå®¶çš„å¤§æ¨¡å‹ã€‚èº«è¾¹çš„äººéƒ½åœ¨å¿™ç€å¦‚ä½•åœ¨å‚ç›´é¢†åŸŸé‡Œæ€¼æ•°æ®ï¼Œå„ç§èŠ±å¼å¾®è°ƒã€‚æœ¬äººå·ä¸è¿‡ï¼Œå·ä¸åŠ¨ï¼Œæ²¡è„‘å­ï¼Œä¸æ‡‚å·ï¼Œé‚æ¢èµ›é“ï¼Œå†³å®šæ•´LLMéƒ¨ç½²ã€‚è°¨ä»¥æ­¤æ–‡è®°å½•ç ´å·ä¹‹è·¯çš„å­¦ä¹ å¿ƒå¾—ã€‚å¸Œæœ›æœ¬repoå¯ä»¥åšæŒæ›´æ–°ã€‚ğŸ·

# æ¨¡å‹
å¤§æ¨¡å‹ç»ƒæ‰‹çš„å‰æä¹‹ä¸€å°±æ˜¯æœ‰æ¨¡å‹ï¼Œè¿™æ„å‘³ç€å’±åªèƒ½ç”¨å¼€æºæ¨¡å‹ï¼Œé—­æºæ¨¡å‹å’±å¤Ÿä¸ç€ï¼Œæ‰€ä»¥å…ˆæ¥çœ‹çœ‹æœ‰å“ªäº›å¯ç”¨çš„ä¸­æ–‡å¼€æºæ¨¡å‹ã€‚è‡³äºä¸ºä»€ä¹ˆè¦ç”¨ä¸­æ–‡æ¨¡å‹ï¼Œè¿™ä¸ªé—®é¢˜ä½ è§‰å¾—å‘¢ï¼Ÿ

## GLMåŸºåº§
+ ChatGLMç³»åˆ—
  -  [ChatGLM-6b](https://github.com/THUDM/ChatGLM-6B) ![](https://img.shields.io/github/stars/THUDM/ChatGLM-6B.svg) æ¨¡å‹æ˜¯ç”±æ¸…åå¤§å­¦å’Œæ™ºæºè”åˆå‘å¸ƒçš„ä¸­æ–‡å¼€æºæ¨¡å‹ï¼ŒåŸºäºGeneral Language Model (GM) æ¶æ„ï¼Œåœ¨1T tokenä¸Šè®­ç»ƒï¼Œæ”¯æŒ2Kä¸Šä¸‹æ–‡ã€‚åœ¨INT4é‡åŒ–ä¹‹ååªéœ€è¦6GBæ˜¾å­˜å³å¯å®Œæˆéƒ¨ç½²ï¼Œå¯ä»¥è¿è¡Œåœ¨æ¶ˆè´¹çº§æ˜¾å¡ä¸Šã€‚
  -   [ChatGLM2-6b](https://github.com/THUDM/ChatGLM2-6B) ![](https://img.shields.io/github/stars/THUDM/ChatGLM2-6B.svg)  åœ¨ChatGLM-6bçš„åŸºç¡€ä¸Šåšäº†ä¸‰ä¸ªæ–¹é¢çš„æ”¹è¿›ï¼š1ï¼‰ä½¿ç”¨äº†GLMçš„æ··åˆç›®æ ‡å‡½æ•°ï¼Œåœ¨1.4T tokenä¸Šå¯¹é½äººç±»åå¥½ï¼Œæ€§èƒ½ä¸Šå¤§å¹…æå‡ï¼›2ï¼‰åŸºäºFlashAttentionæŠ€æœ¯ï¼Œæ”¯æŒ32Kä¸Šä¸‹æ–‡ï¼›3ï¼‰åŸºäºMulti-Query-AttentionæŠ€æœ¯ï¼Œæ¨ç†é€Ÿåº¦æå‡42%
  -    [ChatGLM3-6b](https://github.com/THUDM/ChatGLM3) ![](https://img.shields.io/github/stars/THUDM/ChatGLM3.svg)  ä½¿ç”¨äº†æ›´å¤šæ ·çš„è®­ç»ƒæ•°æ®ï¼Œæ‹¥æœ‰10bä»¥ä¸‹åŸºç¡€æ¨¡å‹æ¨¡å‹ä¸­æœ€å¼ºæ€§èƒ½ï¼›é‡‡ç”¨äº†å…¨æ–°çš„Promptæ ¼å¼ï¼ŒåŸç”Ÿæ”¯æŒå·¥å…·ä»£è°ƒç”¨ã€ä»£ç æ‰§è¡Œå’ŒAgentç­‰ä»»åŠ¡ã€‚

## LLaMAåŸºåº§
+ LLaMAç³»åˆ—
  - [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) ![](https://img.shields.io/github/stars/ymcui/Chinese-LLaMA-Alpaca.svg) é¡¹ç›®åŒ…æ‹¬ä¸­æ–‡LLaMAå’Œä¸­æ–‡Alpacaä¸¤ä¸ªç³»åˆ—æ¨¡å‹ï¼Œå‰è€…é‡‡ç”¨å› æœè¯­è¨€æ¨¡å‹ï¼ˆCausual Lanugage Model, CLMï¼‰çš„æ–¹å¼è¿›è¡ŒäºŒæ¬¡é¢„è®­ç»ƒï¼Œåè€…ä½¿ç”¨æŒ‡ä»¤å¾®è°ƒçš„æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚è€Œä¸”ç”±äºä½¿ç”¨çš„æ˜¯æœªæ­£å¼å¼€æºçš„LLaMAæ¨¡å‹ï¼Œæ‰€ä»¥è¿™ä¸ªé¡¹ç›®ä¸­å‘å¸ƒçš„æ˜¯LoRAæƒé‡ã€‚
  -  [Llama2-Chinese](https://github.com/FlagAlpha/Llama2-Chinese)   ![](https://img.shields.io/github/stars/FlagAlpha/Llama2-Chinese.svg) é¡¹ç›®åŒæ ·åŒ…æ‹¬ä¸¤ä¸ªç³»åˆ—çš„LLaMAæ¨¡å‹ï¼Œä¸€ä¸ªæ˜¯åŸºäºLLaMA2-Chatè¿›è¡ŒæŒ‡ä»¤å¾®è°ƒçš„Llama2-Chinese-Chatç³»åˆ—æ¨¡å‹ï¼Œä¸€ä¸ªåŸºäºä¸­æ–‡æ•°æ®è¿›è¡Œé¢„è®­ç»ƒçš„Atomç³»åˆ—æ¨¡å‹ã€‚

+ Baichuanç³»åˆ—
	- Baichuanæ˜¯ç”±ç™¾å·æ™ºèƒ½å¼€å‘çš„ä¸­æ–‡LLMæ¨¡å‹ï¼Œé‡‡ç”¨äº†ä¸LLaMAä¸€æ ·çš„æ¨¡å‹è®¾è®¡ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œä½¿ç”¨äº†FlashAttentionã€ç®—å­åˆ‡åˆ†ã€é€šè®¯ä¼˜åŒ–ç­‰æŠ€ã€‚[Baichuan-7b](https://github.com/baichuan-inc/baichuan-7B) ![](https://img.shields.io/github/stars/baichuan-inc/baichuan-7B.svg)  å’Œ[baichuan-13b](https://github.com/baichuan-inc/Baichuan-13B) ![](https://img.shields.io/github/stars/baichuan-inc/baichuan-13B.svg) æ”¯æŒçš„ä¸Šä¸‹æ–‡é•¿åº¦éƒ½æ˜¯4096ï¼Œåè€…åœ¨æ›´å¤šæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”ä½¿ç”¨äº†ALiBiä½ç½®ç¼–ç ã€‚ç™¾å·æ™ºèƒ½è¿˜å¼€æºäº†int4å’Œint8çš„é‡åŒ–ç‰ˆæœ¬ï¼Œç”¨äºæ¨ç†åŠ é€Ÿï¼Œå¯ä»¥åœ¨æ¶ˆè´¹çº§æ˜¾å¡ä¸Šéƒ¨ç½²ã€‚
	- [Baichuan2](https://github.com/baichuan-inc/Baichuan2) ![](https://img.shields.io/github/stars/baichuan-inc/Baichuan2.svg) åœ¨æ›´å¤§ã€æ›´å¤šæ ·çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒ

+ Qwenç³»åˆ—
	- [Qwen](https://github.com/QwenLM/Qwen) ![](https://img.shields.io/github/stars/QwenLM/Qwen.svg) æ˜¯é˜¿é‡Œå‘å¸ƒçš„é€šä¹‰åƒé—®ç³»åˆ—å¤§æ¨¡å‹ï¼ŒåŒæ ·é‡‡ç”¨äº†LLaMAçš„æ¨¡å‹æ¶æ„ï¼Œåœ¨3T tokenä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œæ”¯æŒ8Kä¸Šä¸‹æ–‡ã€‚

+ ä¹¦ç”ŸÂ·æµ¦è¯­ï¼ˆInternLMï¼‰ç³»åˆ—
  - [ä¹¦ç”ŸÂ·æµ¦è¯­2](https://github.com/InternLM/InternLM) ![](https://img.shields.io/github/stars/InternLM/InternLM.svg)  ç”±å•†æ±¤ç§‘æŠ€ã€ä¸Šæµ·AIå®éªŒå®¤è”åˆé¦™æ¸¯ä¸­æ–‡å¤§å­¦ã€å¤æ—¦å¤§å­¦å’Œä¸Šæµ·äº¤é€šå¤§å­¦å…±åŒå‘å¸ƒï¼Œåœ¨ä¹¦ç”ŸÂ·æµ¦è¯­çš„åŸºç¡€ä¸Šä½¿ç”¨äº†æ›´å¤§ã€æ›´å¤šæ ·çš„æ•°æ®ï¼Œåœ¨ä»£ç ã€æ•°ç†ã€åˆ›ä½œç­‰æ–¹é¢çš„æ€§èƒ½éƒ½æœ‰å¤§å¹…æå‡ã€‚

+ ChatRWKVç³»åˆ—
  - [ChatRWKV](https://github.com/BlinkDL/ChatRWKV) ![](https://img.shields.io/github/stars/BlinkDL/ChatRWKV.svg) å¼€æºäº†ä¸€ç³»åˆ—åŸºäºRWKVç»“æ„çš„æ¨¡å‹ï¼ŒRWKVæ˜¯ä¸€ä¸ªä½¿ç”¨RNNç»“æ„çš„æ¨¡å‹ï¼Œå…¶ç‰¹ç‚¹æ˜¯æ— è®ºä¸Šä¸‹æ–‡é•¿åº¦æ˜¯å¤šå°‘ï¼Œå…¶é€Ÿåº¦ä¸å˜ï¼Œå ç”¨æ˜¾å­˜ä¸å˜ã€‚

å…¶ä»–æ›´å¤šçš„å¼€æºä¸­æ–‡æ¨¡å‹ä»‹ç»å¯ä»¥å‚è€ƒ[è¿™ä¸ªrepo](https://github.com/HqWu-HITCS/Awesome-Chinese-LLM)ã€‚ä»ä¸Šé¢åˆ—å‡ºçš„starè¾ƒå¤šçš„æ¨¡å‹æ¥çœ‹ï¼Œå›½å†…ç›®å‰å¼€æºçš„LLMä¸»è¦åŸºäºGLMã€LLaMAå’ŒRWKVä¸‰ç§æ¨¡å‹æ¶æ„ã€‚

# æ¨ç†å’Œéƒ¨ç½²æ¡†æ¶
æœ‰äº†æ¨¡å‹æ¥ä¸‹æ¥å°±æ˜¯ç¡®å®šæ¨ç†éƒ¨ç½²æ¡†æ¶ï¼Œéšç€LLMçš„è“¬å‹ƒå‘å±•ï¼ŒLLMå¯¹åº”çš„æ¨ç†éƒ¨ç½²æ¡†æ¶ä¹Ÿæ˜¯ç™¾èŠ±é½æ”¾ã€çœ¼èŠ±ç¼­ä¹±ã€‚æœ‰å¸¸ç”¨çš„transformersã€onnxæ¡†æ¶ï¼Œä¹Ÿæœ‰ä¸“é—¨é’ˆå¯¹LLMåšäº†ä¼˜åŒ–çš„éƒ¨ç½²æ¡†æ¶ï¼Œå¦‚vLLMã€TensorRT-LLMç­‰ã€‚æœ‰C++è¯­è¨€å®ç°çš„llama.cppï¼Œä¹Ÿæœ‰ç§»åŠ¨ç«¯éƒ¨ç½²æ¡†æ¶ChatGLM-MNNï¼Œè¿˜æœ‰æ”¯æŒåœ¨TPUä¸Šéƒ¨ç½²çš„æ¡†æ¶ChatGLM2-TPUç­‰ç­‰ã€‚

| æ¨ç†å’Œéƒ¨ç½²æ¡†æ¶                                               | ç‰¹ç‚¹                                                         | ä¼˜åŒ–æ–¹æ³•                                                     | é‡åŒ–æ–¹æ³•                                   | æµå¼æ¨ç†           | æŠ€æœ¯æŠ¥å‘Š                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------ | ------------------ | ------------------------------------------------------------ |
| [HuggingFace transformers, HF](https://github.com/huggingface/transformers) ![GitHub Repo stars](https://img.shields.io/github/stars/huggingface/transformers) | åŸç”Ÿtransformersæ¨ç†æ¥å£                                     | KV Cache                                                     |                                            |                    |                                                              |
| [HuggingFace Transformer Text Generation Inference, TGI](https://github.com/huggingface/text-generation-inference) ![GitHub Repo stars](https://img.shields.io/github/stars/huggingface/text-generation-inference) | huggingfaceæä¾›äº†LLMæ–‡æœ¬ç”Ÿæˆæ¨ç†åº“                           | TP, CB, FA, PA                                               | bitsandbytes, GPTQ, EETQ, AWQ              | :white_check_mark: |                                                              |
| [llama.cpp](https://github.com/ggerganov/llama.cpp) ![GitHub Repo stars](https://img.shields.io/github/stars/ggerganov/llama.cpp) | çº¯C/C++å¼€å‘çš„éƒ¨ç½²æ¡†æ¶ï¼Œè¿˜æ”¯æŒAppleèŠ¯ç‰‡å’Œå¤šç§é‡åŒ–æ–¹å¼ï¼Œæä¾›äº†å¤šç§è¯­è¨€çš„æ¥å£ | 2/3/4/5/6/8-bit quantization, ç”¨æˆ·è‡ªå®šä¹‰CUDAç®—å­ï¼ŒCPU+GPUæ··åˆæ¨ç† |                                            |                    |                                                              |
| [text-generation-webui](https://github.com/oobabooga/text-generation-webui) ![GitHub Repo stars](https://img.shields.io/github/stars/oobabooga/text-generation-webui) | ä¸»è¦ç”¨äºéœ€è¦æä¾›web UIäº¤äº’ç•Œé¢çš„éƒ¨ç½²æ–¹å¼ï¼Œæ‰€ä»¥æ¨ç†é€Ÿåº¦å’Œå¹¶å‘é‡å¹¶ä¸æ˜¯å…¶è€ƒè™‘çš„è¦ç‚¹ |                                                              |                                            |                    |                                                              |
| [vLLM](https://github.com/vllm-project/vllm) ![GitHub Repo stars](https://img.shields.io/github/stars/vllm-project/vllm) | ä½¿ç”¨äº†PagedAttentionæŠ€æœ¯é™ä½æ˜¾å­˜å ç”¨ï¼Œæ¨ç†ååé‡æ¯”HFé«˜24xï¼Œæ¯”TGIé«˜3.5x | PA, CB, ä¼˜åŒ–äº†CUDAç®—å­, TP                                   | GPTQ, AWQ, SqueezeLLM, FP8 KV Cache        | :white_check_mark: | [LINK](https://blog.vllm.ai/2023/06/20/vllm.html)            |
| [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) ![GitHub Repo stars](https://img.shields.io/github/stars/NVIDIA/TensorRT-LLM) | é›†æˆäº†TensorRTçš„ä¸“é—¨ç”¨äºåœ¨è‹±ä¼Ÿè¾¾GPUä¸Šéƒ¨ç½²LLMçš„SDKï¼Œæä¾›äº†pythonå’ŒC++æ¥å£ï¼›æ”¯æŒé›†æˆè‹±ä¼Ÿè¾¾è‡ªå®¶çš„Tritonæ¨ç†æœåŠ¡å™¨ | TP, PP, A16W8, A16W4, CB, PA, FMHA                           | SmoothQuant                                |                    | [LINK](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/performance.md) |
| [JittorLLMs](https://github.com/Jittor/JittorLLMs) ![GitHub Repo stars](https://img.shields.io/github/stars/Jittor/JittorLLMs) | å¤§å¹…é™ä½ç¡¬ä»¶è¦æ±‚ï¼Œ2GBå†…å­˜å³å¯éƒ¨ç½²LLMï¼›æ¨¡å‹å¯å¿«é€Ÿé€‚é…å„ç§è®¡ç®—è®¾å¤‡ï¼›é€šè¿‡é›¶æ‹·è´æŠ€æœ¯ï¼Œå®ç°40%åŠ è½½åŠ é€Ÿï¼›é€šè¿‡å…ƒç®—å­ç¼–è¯‘ä¼˜åŒ–ï¼Œè®¡ç®—é€Ÿåº¦æå‡20%+ |                                                              |                                            |                    |                                                              |
| [InferLLM](https://github.com/MegEngine/InferLLM) ![GitHub Repo stars](https://img.shields.io/github/stars/MegEngine/InferLLM) | æ—·è§†æ¨å‡ºçš„LLMæ¨ç†æ¡†æ¶ï¼Œåœ¨llama.cppçš„åŸºç¡€ä¸Šä¼˜åŒ–äº†ç¼–ç ï¼›è‡³äºä¸llama.cppçš„æ¨ç†é€Ÿåº¦å¯¹æ¯”ï¼Œreadmeä¸­å¹¶æ²¡æœ‰æåŠ |                                                              |                                            |                    |                                                              |
| [mnn-llm](https://github.com/wangzhaode/mnn-llm) ![GitHub Repo stars](https://img.shields.io/github/stars/wangzhaode/mnn-llm) | ç”¨äºåœ¨å®‰å“ç³»ç»Ÿä¸Šéƒ¨ç½²LLMçš„æ¡†æ¶ï¼Œæ”¯æŒonnxå’Œmnnæ¨¡å‹æ ¼å¼         |                                                              |                                            |                    | [LINK](https://github.com/wangzhaode/mnn-llm?tab=readme-ov-file#cpu-4%E7%BA%BF%E7%A8%8B%E9%80%9F%E5%BA%A6-prefill--decode-toks) |
| [LMDeploy](https://github.com/InternLM/lmdeploy) ![GitHub Repo stars](https://img.shields.io/github/stars/InternLM/lmdeploy) | ç”±MMDeployå’ŒMMRazorå›¢é˜Ÿè”åˆå¼€å‘ï¼Œåœ¨InternLMé¡¹ç›®æ¨å‡ºçš„éƒ¨ç½²æ¡†æ¶ã€‚æ¨ç†æ€§èƒ½ä¸ºvLLMçš„1.8å€ã€‚åç«¯æ”¯æŒTurboMindå’ŒPyTorchä¸¤ç§å¼•æ“ï¼Œå‰è€…æ³¨é‡æ¨ç†é€Ÿåº¦ï¼Œåè€…æ³¨é‡å¼€å‘æ•ˆç‡ã€‚ | CBï¼Œ Blocked KV Cache, åŠ¨æ€æ‹†åˆ†å’Œèåˆ, TP                    |                                            |                    | [LINK](https://github.com/InternLM/lmdeploy/blob/main/docs/en/benchmark/a100_fp16.md) |
| [CTranslate2](https://github.com/OpenNMT/CTranslate2) ![GitHub Repo stars](https://img.shields.io/github/stars/OpenNMT/CTranslate2) | çº¯C++å®ç°çš„æé«˜Transformerç»“æ„æ¨¡å‹æ¨ç†é€Ÿåº¦çš„æ¡†æ¶ï¼Œæä¾›pythonæ¥å£ã€‚ä»ç¬”è€…ä½¿ç”¨çš„æƒ…å†µæ¥çœ‹åŠ é€Ÿæ•ˆæœä¸€èˆ¬ï¼Œå¹¶ä¸”ä¸å¤ªé€‚åˆLLMæ¨ç† |                                                              |                                            |                    | [LINK](https://github.com/OpenNMT/CTranslate2?tab=readme-ov-file#cpu) |
| [OpenLLM](https://github.com/bentoml/OpenLLM) ![GitHub Repo stars](https://img.shields.io/github/stars/bentoml/OpenLLM) | é€šè¿‡é›†æˆPytorchã€vLLMã€PEFTç­‰å·¥å…·ï¼Œæ”¯æŒLoRAå¾®è°ƒå’Œéƒ¨ç½²çš„å¼€æºæ¡†æ¶ã€‚è¿˜æ”¯æŒä¸BentoMLã€OpenAIã€LangChainç­‰å·¥å…·é›†æˆã€‚ | CB,                                                          | LLM.int8, SpQR(int4), AWQ, GPTQ, SqueezeLM | :white_check_mark: |                                                              |
| [MLC-LLM](https://github.com/mlc-ai/mlc-llm) ![GitHub Repo stars](https://img.shields.io/github/stars/mlc-ai/mlc-llm) | æ”¯æŒåœ¨å¤šç§è®¾å¤‡å’Œå¹³å°ä¸Šï¼Œä½¿ç”¨åŸç”Ÿapiå¼€å‘å„ç§LLMæ¨¡å‹ï¼Œä»¥å®ç°æœ€å¤§ç¨‹åº¦çš„ä¼˜åŒ–ã€‚æ¨ç†é€Ÿåº¦æ˜¯vLLMçš„1.4~2.5å€ã€‚ |                                                              |                                            |                    |                                                              |
| [LightLLM](https://github.com/ModelTC/lightllm) ![GitHub Repo stars](https://img.shields.io/github/stars/ModelTC/lightllm) | LightLLMæ›´å¤šçš„æ˜¯ä¸€ä¸ªæœåŠ¡åˆ†å‘å’Œå¤„ç†æ¡†æ¶ï¼Œä¸»è¦é€šè¿‡å¼‚æ­¥å¤„ç†tokenizationã€æ¨¡å‹æ¨ç†å’Œdetokenizationæ¥æé«˜æ¨¡å‹æ¨ç†æ€§èƒ½ | CBï¼ŒFAï¼ŒTPï¼ŒTAï¼ŒInt8 K/V Cache                               |                                            |                    |                                                              |
| [AirLLM](https://github.com/lyogavin/Anima/tree/main/air_llm) ![GitHub Repo stars](https://img.shields.io/github/stars/lyogavin/Anima) | å®ç°äº†åœ¨4GBæ˜¾å­˜ä¸Šè¿è¡Œ70Bæ¨¡å‹ï¼Œä½¿ç”¨äº†åˆ†å±‚æ¨ç†ã€FAã€æ¨¡å‹æ–‡ä»¶æ‹†è§£ã€metaè®¾å¤‡ç­‰æŠ€æœ¯ |                                                              |                                            |                    | [Link1](https://arxiv.org/abs/2212.09720)  [Link2](https://zhuanlan.zhihu.com/p/667474769) |



**å¤‡æ³¨**ï¼š Tensor Parallelism (TP), Pipeline Parallelism (PP), Continuous Batching (CB), Flash Attention (FA), Paged Attention(PA),  Fused MultiHeadAttention (FMHA), Token Attention (TA)

é€šè¿‡ä¸Šè¡¨å¯ä»¥çœ‹åˆ°ï¼Œç›®å‰å¼€æºäº†éå¸¸å¤šç”¨äºLLMæ¨ç†éƒ¨ç½²çš„æ¡†æ¶ï¼Œå…¶ä¸­ä½¿ç”¨è¾ƒå¤šçš„æœ‰ï¼švLLM, TensorRT-LLM, JittorLM, LMDeploy, OpenLLM, MLC-LLM, AirLLMç­‰ã€‚è¿™äº›æ¡†æ¶æ™®éä½¿ç”¨äº†AttentionåŠ é€ŸæŠ€æœ¯ã€å¤šç§é‡åŒ–æ–¹æ³•ã€Continuous Batchingã€å¼ é‡å¹¶è¡Œç­‰æŠ€æœ¯ã€‚

# æ˜¾å¡
æœ‰äº†æ¨¡å‹å’Œæ¨ç†çŸ¿æ¡†æ¶ï¼Œæ¥ä¸‹æ¥å°±æ˜¯éƒ¨ç½²æ—¶ä½¿ç”¨çš„ç¡¬ä»¶è®¾å¤‡ã€‚å› ä¸ºLLMçš„è®¡ç®—éœ€æ±‚ï¼Œä¸€èˆ¬æ¥è¯´éƒ½æ˜¯åœ¨GPUä¸Šéƒ¨ç½²LLMã€‚ç›®å‰å¸‚é¢ä¸ŠNvidiaã€AMDã€Appleå’ŒIntelå‡ å®¶å‡ºçš„GPUï¼Œä½†æ˜¯åº”ç”¨æœ€å¹¿æ³›çš„æ˜¯Nvidiaçš„GPUã€‚

**GPUæœ‰å‡ ä¸ªå…³é”®çš„å‚æ•°éœ€è¦å…³æ³¨ï¼š**

+** cuda coreå’Œtensor core**ï¼š è¿™ä¸¤ä¸ªæ¦‚å¿µæ˜¯ç”¨åœ¨Nvidiaçš„GPUä¸Šçš„ï¼Œå®ƒä»¬éƒ½æ˜¯è¿ç®—å•å…ƒï¼Œä¸»è¦çš„å·®å¼‚çš„ç®—åŠ›å¤§å°ã€‚cuda coreæ˜¯å…¨èƒ½å‹æµ®ç‚¹è¿ç®—å•å…ƒï¼Œåœ¨Fermiæ¶æ„ä¹‹é—´è¢«ç§°ä¸ºstreaming processorsï¼›è€Œtensor coreæ˜¯ä»Voltaæ¶æ„å¼€å§‹æ¨å‡ºçš„ä¸“é—¨ç”¨äºçŸ©é˜µè¿ç®—çš„è¿ç®—å•å…ƒã€‚åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œå¤§éƒ¨åˆ†çš„ã€è€—æ—¶çš„è¿ç®—éƒ½æ˜¯çŸ©é˜µç›¸å…³çš„è¿ç®—ï¼Œç‰¹åˆ«æ˜¯çŸ©é˜µä¹˜æ³•ï¼Œå› æ­¤tensor coreä¸“é—¨ä¸ºçŸ©é˜µè¿ç®—è¿›è¡Œäº†åŠ é€Ÿã€‚
+ **æ˜¾å­˜å¤§å°**ï¼šæ˜¾å­˜çš„å¤§å°å†³å®šäº†GPUå¯ä»¥åŠ è½½å¤šå°‘æ•°æ®ï¼Œå½“æ˜¾å­˜è¶Šå¤§å¯ä»¥è®¡ç®—çš„æ•°æ®å°±è¶Šå¤šã€‚
+ **æ˜¾å­˜å¸¦å®½**ï¼šå†³å®šäº†GPUå°†æ•°æ®ä»æ˜¾å­˜ç§»åŠ¨åˆ°è®¡ç®—æ ¸å¿ƒçš„é€Ÿåº¦ï¼Œé€Ÿåº¦è¶Šå¿«å®ŒæˆæŸä¸ªè¿ç®—çš„é€Ÿåº¦ä¹Ÿæ›´å¿«ã€‚
+ **è®¡ç®—èƒ½åŠ›**ï¼šè¡¨ç¤ºæ¯ç§’çš„æµ®ç‚¹è¿ç®—é‡ã€‚æ ¹æ®æ•°æ®çš„ç²¾åº¦åˆåˆ†ä¸ºåŒç²¾åº¦ï¼ˆfp64ï¼‰ã€å•ç²¾åº¦ï¼ˆfp32ï¼‰å’ŒåŠç²¾åº¦ï¼ˆfp16ï¼‰æµ®ç‚¹è®¡ç®—é‡ï¼Œä¸€èˆ¬æ¥è¯´ä½¿ç”¨åŒç²¾åº¦æµ®ç‚¹è®¡ç®—é‡æ¥è¡¡é‡ç®—åŠ›ã€‚



| æ˜¾å¡      | æ¶æ„         | æ˜¾å­˜ï¼ˆGBï¼‰ | FP64 Tensor Coresï¼ˆTFLOPSï¼‰ | å¸¦å®½ï¼ˆTB/sï¼‰ | TF32               | FP16               | BF16               | FP8                | INT8               | è¿æ¥                                                         |
| --------- | ------------ | ---------- | --------------------------- | ------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------------------------------------------------ |
| H200-SXM  | Hopper       | 141        | 67                          | 4.8          | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | [LINK](https://www.nvidia.com/zh-tw/data-center/h200/)       |
| H100-NVL  | Hopper       | 188        | 134                         | 7.8          | :x:                | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | [LINK](https://www.nvidia.com/zh-tw/data-center/h100/)       |
| A100-PCIe | Ampere       | 80         | 19.5                        | 1.935        | :white_check_mark: | :white_check_mark: | :white_check_mark: | :x:                | :white_check_mark: | [LINK](https://www.nvidia.com/zh-tw/data-center/a100/)       |
| V100-NVL  | Volta        | 32         | 7.8                         | 0.9          | :white_check_mark: | :white_check_mark: | :x:                | :x:                | :white_check_mark: | [LINK](https://www.nvidia.com/zh-tw/data-center/v100/)       |
| V100-PCIE | Volta        | 32         | 7                           | 0.9          | :white_check_mark: | :white_check_mark: | :x:                | :x:                | :white_check_mark: | [LINK](https://www.nvidia.com/zh-tw/data-center/v100/)       |
| RTX 3090  | Ampere       | 24         |                             |              | :x:                | :x:                | :x:                | :x:                | :x:                | [LINK](https://www.nvidia.cn/geforce/graphics-cards/30-series/rtx-3090-3090ti/) |
| RTX 4090  | Ada Lovelace | 24         |                             |              | :x:                | :x:                | :x:                | :x:                | :x:                | [LINK](https://www.nvidia.cn/geforce/graphics-cards/40-series/rtx-4090-d/) |



**å‚è€ƒèµ„æ–™ï¼š**
+ GPUæ ¸å¿ƒæŒ‡æ ‡ï¼šhttps://blog.csdn.net/chongbin007/article/details/123897149
+ cuda coreå’Œtensor coreçš„åŒºåˆ«ï¼šhttps://www.zhihu.com/question/451127498
+ æµ®ç‚¹è®¡ç®—èƒ½åŠ›ï¼šhttps://blog.csdn.net/zong596568821xp/article/details/103957058
+ æµ®ç‚¹è®¡ç®—èƒ½åŠ›ï¼šhttps://www.jishulink.com/post/1205946
+ å·…å³°å¯¹å†³ï¼šè‹±ä¼Ÿè¾¾ V100ã€A100/800ã€H100/800 GPU å¯¹æ¯”: https://zhuanlan.zhihu.com/p/658054971


